{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCRShV8glg4o"
      },
      "source": [
        "# **Prediction of Genetic Associations in ALS Through NLP and Complex Network Analysis**\n",
        "\n",
        "This research project aims to predict candidate genes in Amyotrophic Lateral Sclerosis (ALS) using Natural Language Processing (NLP) and complex network analysis techniques.\n",
        "\n",
        "- **Author:** JoÃ£o Pedro Viguini T. T. Correa  \n",
        "- **Supervisor:** Prof. Dr. Ricardo Cerri\n",
        "\n",
        "This research is supported by FAPESP (2025/06512-0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwXGWiJKX6RW"
      },
      "source": [
        "# Package Installation\n",
        "\n",
        "- **[IMPORTANT]** Please ensure that all necessary files are downloaded from the GitHub repository and uploaded to your Google Drive.\n",
        "\n",
        "- The steps below detail the installation process for the required packages and models used in this study.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8EXAVpDKura"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EvEHVm6DX8n3"
      },
      "outputs": [],
      "source": [
        "!pip install -r ./drive/MyDrive/IC_2025/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrJBjo6KQhtV"
      },
      "source": [
        "Install spaCy models for NER and tokenization --> It should be inside your Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hjzEHLncdb4S"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade drive/MyDrive/IC_2025/en_ner_bionlp13cg_md-0.5.4.tar.gz --no-deps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Y3KilBXn2Q"
      },
      "source": [
        "# Import\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Restart the session before running this cell.**"
      ],
      "metadata": {
        "id": "xLrio4Xmbx7V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpQm1mMnMGAR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import urllib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from Bio import Entrez\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import spacy\n",
        "from tqdm import tqdm\n",
        "\n",
        "try:\n",
        "    import mygene\n",
        "    MYGENE_AVAILABLE = True\n",
        "except Exception:\n",
        "    print(\"mygene not available\")\n",
        "    MYGENE_AVAILABLE = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZBf5PIkMIqm"
      },
      "source": [
        "# Configs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7F20QW8MKQs"
      },
      "outputs": [],
      "source": [
        "Entrez.email = \"ENTREZ_EMAIL\" # replace\n",
        "API_KEY = \"ENTREZ_API\"   # replace\n",
        "YEAR_START = 2000\n",
        "YEAR_END = 2010\n",
        "MAX_ARTICLES = 100 # how many articles you want to retrieve\n",
        "SLEEP_TIME = 0.34\n",
        "MAX_RETRIES = 3\n",
        "CHUNK_SIZE = 200\n",
        "VALIDATE_WITH_MYGENE = True\n",
        "MYGENE_BATCH_SIZE = 1000\n",
        "\n",
        "\n",
        "base_query = (\n",
        "    '(\"amyotrophic lateral sclerosis\"[tiab] OR \"motor neuron disease\"[tiab] OR MND[tiab] OR ALS[tiab]) AND '\n",
        "    '(\"gene\"[tiab] OR \"genes\"[tiab] OR genetic[tiab] OR mutation*[tiab] OR polymorphism*[tiab] OR \"Genome-Wide Association Study\"[Mesh] OR GWAS[tiab])'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm52yncVMUX2"
      },
      "source": [
        "# Loading NLP models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3Wb2Jh6MVzJ"
      },
      "outputs": [],
      "source": [
        "print(\"Loading NLP models...\")\n",
        "nlp_ner = None\n",
        "\n",
        "# spaCy NER\n",
        "try:\n",
        "    nlp_ner = spacy.load(\"en_ner_bionlp13cg_md\", disable=[\"tagger\", \"parser\"])\n",
        "except Exception as e:\n",
        "    print(\"Warning: could not load en_ner_bionlp13cg_md (NER). Error:\", e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XACFzndMqmy"
      },
      "source": [
        "# Preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsZpmVygMsf3"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = re.sub(r'<[^>]+>', ' ', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s\\-]', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text.lower()\n",
        "\n",
        "\n",
        "\n",
        "GENE_STOPWORDS = set([\n",
        "    \"THE\", \"AND\", \"WITH\", \"FOR\", \"WAS\", \"WERE\", \"ARE\", \"OUR\", \"FROM\",\n",
        "    \"THIS\", \"THAT\", \"THAN\", \"DISEASE\", \"PATIENT\", \"PATIENTS\", \"GENETIC\", \"RISK\",\n",
        "    \"STUDY\", \"GENE\", \"GENES\", \"ANALYSIS\", \"RESULT\", \"RESULTS\", \"DATA\", \"MODEL\",\n",
        "    \"MODELS\", \"TYPE\", \"CASE\", \"CASES\", \"ALS\", \"LATERAL\", \"SCLEROSIS\", \"MOTOR\",\n",
        "    \"NEURON\", \"DNA\", \"RNA\", \"PROTEIN\", \"CELL\", \"CELLS\", \"TISSUE\", \"BRAIN\",\n",
        "    \"NEURONS\", \"MOUSE\", \"MICE\",\n",
        "\n",
        "    \"OF\", \"IN\", \"TO\", \"ON\", \"BY\", \"AS\", \"AN\", \"OR\", \"IS\", \"BE\", \"WE\",\n",
        "    \"NOT\", \"THESE\", \"HAVE\", \"HAS\", \"WITHIN\", \"FOUND\", \"US\", \"INCREASE\", \"IMPACT\"\n",
        "])\n",
        "\n",
        "\n",
        "# regex patterns as a fallback\n",
        "REGEX_PATTERNS = [\n",
        "    r\"\\bC\\d+ORF\\d+\\b\",           # ex: C9ORF72\n",
        "    r\"\\bRS\\d{3,9}\\b\",              # SNP ids: rs123456\n",
        "    r\"\\b[A-Z]{2,4}-\\d{1,3}\\b\",    # ex: ABC-1, TDP-43\n",
        "    r\"\\b[A-Z]{3,6}[0-9]{0,3}\\b\"  # ex: SOD1, TP53\n",
        "]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPHg_jdxNNnE"
      },
      "source": [
        "# Gene extraction using NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wV1FWuXZNWdm"
      },
      "outputs": [],
      "source": [
        "def extract_genes_unbiased(text):\n",
        "    \"\"\"\n",
        "    - Extract gene candidates from a text (NER when available and regex as fallback).\n",
        "\n",
        "    - Receive the original text (with capital letters/punctuation) to maximize NER retrieval.\n",
        "\n",
        "    - Return an ordered list of gene-like symbols/tokens in capital letters.\n",
        "    \"\"\"\n",
        "\n",
        "    if not text:\n",
        "        return []\n",
        "    text_str = str(text)\n",
        "    text_upper = text_str.upper()\n",
        "    genes = set()\n",
        "\n",
        "    # NER in the original text\n",
        "    if nlp_ner is not None:\n",
        "        try:\n",
        "            doc = nlp_ner(text_str)\n",
        "            for ent in doc.ents:\n",
        "                label = getattr(ent, 'label_', '')\n",
        "\n",
        "                # NER labels (depends on the model)\n",
        "                if 'GENE' in label.upper() or 'PROTEIN' in label.upper() or 'GENE_PRODUCT' in label.upper():\n",
        "                    norm = re.sub(r'[^A-Za-z0-9]', '', ent.text)\n",
        "                    norm_up = norm.upper()\n",
        "                    if 3 <= len(norm_up) <= 10 and norm_up not in GENE_STOPWORDS: # filter stopwords\n",
        "                        genes.add(norm_up)\n",
        "        except Exception:\n",
        "\n",
        "            # if NER fails, ignore it and continue with regex\n",
        "            pass\n",
        "\n",
        "\n",
        "    # regex patterns\n",
        "    for pattern in REGEX_PATTERNS:\n",
        "        for match in re.findall(pattern, text_upper):\n",
        "\n",
        "            # filter stopwords and tokens too short\n",
        "            if match and match not in GENE_STOPWORDS and len(re.sub(r'[^A-Z0-9]', '', match)) >= 3:\n",
        "                genes.add(match)\n",
        "\n",
        "\n",
        "    # removes tokens that are only numbers\n",
        "    cleaned = set()\n",
        "    for g in genes:\n",
        "        if re.search(r'[A-Z]', g):\n",
        "            cleaned.add(g)\n",
        "    return sorted(cleaned)\n",
        "\n",
        "\n",
        "# validation with mygene\n",
        "def validate_genes_with_mygene(candidate_genes):\n",
        "    \"\"\"\n",
        "    Validates a list of symbols using mygene (batch). Returns a set of validated symbols.\n",
        "\n",
        "    \"\"\"\n",
        "    if not MYGENE_AVAILABLE:\n",
        "        print(\"mygene not available; skipping validation.\")\n",
        "        return set()\n",
        "\n",
        "    mg = mygene.MyGeneInfo()\n",
        "    validated = set()\n",
        "    candidates = list(candidate_genes)\n",
        "\n",
        "    for i in range(0, len(candidates), MYGENE_BATCH_SIZE):\n",
        "        batch = candidates[i:i+MYGENE_BATCH_SIZE]\n",
        "        try:\n",
        "            res = mg.querymany(batch, scopes=['symbol', 'alias', 'name'], fields='symbol,taxid', species='human', entrezonly=False)\n",
        "            for r in res:\n",
        "                # r can signal notfound\n",
        "                if r is None:\n",
        "                    continue\n",
        "\n",
        "                if isinstance(r, dict) and not r.get('notfound', False):\n",
        "                    sym = r.get('symbol')\n",
        "                    taxid = r.get('taxid')\n",
        "\n",
        "                    # human (taxid 9606) or None (some results doesn't have taxid)\n",
        "                    if sym and (taxid is None or int(taxid) == 9606):\n",
        "                        validated.add(sym.upper())\n",
        "        except Exception as e:\n",
        "            print(f\"mygene query batch failed: {e}\")\n",
        "\n",
        "            # in case of error, we just continue\n",
        "            continue\n",
        "\n",
        "    return validated\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV9PqoMCOgmB"
      },
      "source": [
        "# Pubmed article collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt3syVzjSQ1m"
      },
      "outputs": [],
      "source": [
        "def safe_read_abstract(article):\n",
        "\n",
        "    \"\"\"\n",
        "    Extracts pubmed abstracts with tolerance to different formats\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        art = article['MedlineCitation']['Article']\n",
        "        abstract_field = art.get('Abstract')\n",
        "        if not abstract_field:\n",
        "            return ''\n",
        "        abstract_text = abstract_field.get('AbstractText')\n",
        "        if not abstract_text:\n",
        "            return ''\n",
        "\n",
        "        # abstractText can be a list of string or a list of dicts (with #text)\n",
        "        abstract_parts = []\n",
        "        for a in abstract_text:\n",
        "            if isinstance(a, dict):\n",
        "\n",
        "                # some XMLs have {'Label': 'BACKGROUND', 'NlmCategory': '...','#text': '...'}\n",
        "                txt = a.get('#text') or a.get('label') or a.get('Label') or ''\n",
        "                abstract_parts.append(str(txt))\n",
        "            else:\n",
        "                abstract_parts.append(str(a))\n",
        "        return ' '.join([p for p in abstract_parts if p])\n",
        "    except Exception:\n",
        "        return ''\n",
        "\n",
        "\n",
        "def get_genetic_als_articles():\n",
        "\n",
        "    \"\"\"\n",
        "      Search for pubmed articles based on the query\n",
        "    \"\"\"\n",
        "\n",
        "    encoded_query = base_query\n",
        "    articles = []\n",
        "\n",
        "    try:\n",
        "        handle = Entrez.esearch(\n",
        "            db=\"pubmed\",\n",
        "            term=encoded_query,\n",
        "            retmax=0,\n",
        "            mindate=str(YEAR_START),\n",
        "            maxdate=str(YEAR_END),\n",
        "            datetype=\"pdat\",\n",
        "            api_key=API_KEY\n",
        "        )\n",
        "\n",
        "        result = Entrez.read(handle)\n",
        "        handle.close()\n",
        "        total = int(result.get(\"Count\", 0))\n",
        "\n",
        "        print(f\"Found {total} genetic ALS articles\")\n",
        "\n",
        "        if total == 0:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "\n",
        "        for retry in range(MAX_RETRIES):\n",
        "            try:\n",
        "                handle = Entrez.esearch(\n",
        "                    db=\"pubmed\",\n",
        "                    term=encoded_query,\n",
        "                    retmax=MAX_ARTICLES,\n",
        "                    mindate=str(YEAR_START),\n",
        "                    maxdate=str(YEAR_END),\n",
        "                    datetype=\"pdat\",\n",
        "                    usehistory=\"y\",\n",
        "                    api_key=API_KEY\n",
        "                )\n",
        "                search_result = Entrez.read(handle)\n",
        "                handle.close()\n",
        "                id_list = search_result.get(\"IdList\", [])\n",
        "\n",
        "                # Fetch details em batches\n",
        "                for i in tqdm(range(0, min(len(id_list), MAX_ARTICLES), CHUNK_SIZE)):\n",
        "                    batch = id_list[i:i+CHUNK_SIZE]\n",
        "                    fetch_handle = Entrez.efetch(\n",
        "                        db=\"pubmed\",\n",
        "                        id=batch,\n",
        "                        retmode=\"xml\",\n",
        "                        api_key=API_KEY\n",
        "                    )\n",
        "                    try:\n",
        "                        data = Entrez.read(fetch_handle)\n",
        "                    except Exception:\n",
        "\n",
        "                        data = {}\n",
        "                    finally:\n",
        "                        fetch_handle.close()\n",
        "\n",
        "                    for article in data.get('PubmedArticle', []):\n",
        "                        try:\n",
        "                            title = article['MedlineCitation']['Article'].get('ArticleTitle', '')\n",
        "                            abstract = safe_read_abstract(article)\n",
        "                            pmid = str(article['MedlineCitation']['PMID'])\n",
        "                            text = f\"{title} {abstract}\".strip()\n",
        "\n",
        "\n",
        "                            articles.append({\n",
        "                                \"pmid\": pmid,\n",
        "                                \"title\": title,\n",
        "                                \"abstract\": abstract,\n",
        "                                \"text\": text\n",
        "                            })\n",
        "                        except KeyError:\n",
        "                            continue\n",
        "                    time.sleep(SLEEP_TIME)\n",
        "                break\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {retry + 1} failed: {str(e)}\")\n",
        "                time.sleep(2 ** retry)\n",
        "    except Exception as e:\n",
        "        print(f\"Fatal error in PubMed query: {str(e)}\")\n",
        "    return pd.DataFrame(articles)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxADKaG3Sadm"
      },
      "source": [
        "# Useful functions\n",
        "\n",
        "- For training models and calculating the ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dn9NzG0cnMs3"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade torch torchvision torchaudio # these are for using BioBERT\n",
        "!pip install --upgrade --force-reinstall transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBxYroQxlKT-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import fasttext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_mean_embedding(texts, tokenizer, model, device):\n",
        "\n",
        "    \"\"\"calculates mean embedding for genes using BioBERT \"\"\"\n",
        "\n",
        "    # tokenize input texts (genes) and prepare for model\n",
        "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    input_ids = inputs['input_ids']\n",
        "    attention_mask = inputs['attention_mask']\n",
        "    special_ids = set(tokenizer.all_special_ids) # CLS and SEP\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # get model outputs and extract embeddings\n",
        "        outputs = model(**inputs)\n",
        "        token_embeddings = outputs.last_hidden_state\n",
        "\n",
        "        # create mask to exclude special tokens\n",
        "        special_mask = torch.ones_like(attention_mask)\n",
        "\n",
        "        for sid in special_ids:\n",
        "            special_mask = special_mask & (input_ids != sid)\n",
        "        valid_mask = attention_mask.long() & special_mask.long()\n",
        "\n",
        "        # calculate mean pooling of valid tokens\n",
        "        mask_expanded = valid_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "        summed = torch.sum(token_embeddings * mask_expanded, 1)\n",
        "        counts = mask_expanded.sum(1).clamp(min=1)\n",
        "        mean_pooled = summed / counts\n",
        "\n",
        "    return mean_pooled.cpu().numpy()\n",
        "\n",
        "def get_embeddings(gene_list, model, model_type):\n",
        "\n",
        "    \"\"\"\n",
        "      gets embeddings for gene list depending on the model\n",
        "    \"\"\"\n",
        "\n",
        "    # convert genes to lowercase for embedding lookup\n",
        "    lowercase_genes = [g.lower() for g in gene_list]\n",
        "\n",
        "    if model_type == 'fasttext':\n",
        "        # filter genes that exist in fasttext vocabulary\n",
        "        valid_genes = [g for g in lowercase_genes if model.get_word_id(g) != -1]\n",
        "        embeddings = np.array([model.get_word_vector(g) for g in valid_genes])\n",
        "\n",
        "        # return original case genes with their embeddings\n",
        "        original_case_genes = [gene_list[i] for i, g in enumerate(lowercase_genes) if g in valid_genes]\n",
        "        return embeddings, original_case_genes\n",
        "\n",
        "    elif model_type == 'biobert':\n",
        "        # get biobert embeddings for lowercase gene names\n",
        "        tokenizer = model['tokenizer']\n",
        "        biobert_model = model['model']\n",
        "        device = model.get('device', 'cpu')\n",
        "        embeddings = get_mean_embedding(lowercase_genes, tokenizer, biobert_model, device)\n",
        "\n",
        "        return embeddings, gene_list  # returns original case\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
        "\n",
        "\n",
        "def calculate_gene_scores(df):\n",
        "    \"\"\"\n",
        "      calculates TF-IDF scores for genes in the dataframe\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # check for empty dataframe or missing columns\n",
        "    if df.empty or 'genes' not in df.columns or 'clean_text' not in df.columns:\n",
        "        return []\n",
        "\n",
        "    # get unique uppercase genes for final output\n",
        "    uppercase_genes = sorted({gene.upper() for genes_list in df['genes'] for gene in genes_list})\n",
        "\n",
        "    if not uppercase_genes:\n",
        "        return []\n",
        "\n",
        "    # lowercase version for vectorizer matching\n",
        "    lowercase_vocab = [gene.lower() for gene in uppercase_genes]\n",
        "\n",
        "    # get cleaned text documents\n",
        "    docs = df['clean_text'].tolist()\n",
        "\n",
        "    # initialize TF-IDF vectorizer with lowercase vocabulary\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        vocabulary=lowercase_vocab,\n",
        "        lowercase=False,  # already lowercase\n",
        "        token_pattern=r\"(?u)\\b\\w+\\b\"\n",
        "    )\n",
        "\n",
        "    # calculate TF-IDF matrix\n",
        "    tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "    # sum scores across all documents\n",
        "    scores = np.asarray(tfidf_matrix.sum(axis=0)).ravel()\n",
        "\n",
        "    # combine genes with scores and sort\n",
        "    gene_scores = sorted(zip(uppercase_genes, scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return gene_scores\n",
        "\n",
        "\n",
        "def calculate_combined_ranking(gene_score_dict, model, model_type: str, alpha=0.5, known_als_genes=None):\n",
        "\n",
        "    \"\"\"\n",
        "      - Combines TF-IDF and semantic similarity scores for final ranking\n",
        "      - Currently we are only using the semantic similarity as the final score.\n",
        "          - To test a combined score, change the return to use 'combined' instead of 'sim_raw'\n",
        "    \"\"\"\n",
        "\n",
        "    # default known ALS genes if none provided\n",
        "    if known_als_genes is None:\n",
        "        known_als_genes = {\n",
        "            \"ANXA11\", \"C9ORF72\", \"CHCHD10\", \"EPHA4\", \"FUS\", \"HNRNPA1\", \"KIF5A\", \"NEK1\",\n",
        "            \"OPTN\", \"PFN1\", \"SOD1\", \"TARDBP\", \"TDP-43\", \"TDP43\", \"TBK1\", \"UBQLN2\",\n",
        "            \"UNC13A\", \"VAPB\", \"VCP\"\n",
        "        }\n",
        "\n",
        "    known_als_genes = {g.upper() for g in known_als_genes}\n",
        "\n",
        "    # get embeddings for known ALS genes\n",
        "    known_embeddings, valid_known_genes = get_embeddings(\n",
        "        list(known_als_genes), model, model_type\n",
        "    )\n",
        "\n",
        "    if len(valid_known_genes) == 0:\n",
        "        print(\"No known genes found in model.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    known_embeddings = normalize(known_embeddings, axis=1) # normalize it\n",
        "\n",
        "    # get embeddings for candidate genes\n",
        "    candidates = [gene.upper() for gene in gene_score_dict]\n",
        "    candidate_embeddings, valid_candidates = get_embeddings(\n",
        "        candidates, model, model_type\n",
        "    )\n",
        "\n",
        "    if len(valid_candidates) == 0:\n",
        "        print(\"No candidate embeddings generated.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    candidate_embeddings = normalize(candidate_embeddings, axis=1) # normalize it\n",
        "\n",
        "    # cosine similarity between candidates and known genes\n",
        "    similarity_matrix = cosine_similarity(candidate_embeddings, known_embeddings)\n",
        "    max_similarities = np.max(similarity_matrix, axis=1) # take the MAX score\n",
        "\n",
        "    # create results dataframe with combined scores\n",
        "    results_df = pd.DataFrame({\n",
        "        'gene': [g.upper() for g in valid_candidates],\n",
        "        'tfidf_raw': [gene_score_dict[g.upper()] for g in valid_candidates],\n",
        "        'sim_raw': max_similarities\n",
        "    })\n",
        "\n",
        "\n",
        "    # normalize scores before combining them with alpha (just testing)\n",
        "    for col in ['tfidf_raw', 'sim_raw']:\n",
        "        min_val, max_val = results_df[col].min(), results_df[col].max()\n",
        "\n",
        "        results_df[f'{col}_norm'] = (results_df[col] - min_val) / (max_val - min_val + 1e-9)\n",
        "\n",
        "\n",
        "    results_df['combined'] = alpha * results_df['tfidf_raw_norm'] + (1 - alpha) * results_df['sim_raw_norm']\n",
        "\n",
        "    # change for 'combined' if you want the combined score w/ TF-IDF; we're currently using only the semantic similarity.\n",
        "    return results_df.sort_values('sim_raw', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fB9q0kTkK4K"
      },
      "source": [
        "# Helpful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qelY7JMQcD_b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# txt for fasttext\n",
        "def save_corpus_for_fasttext(df, filepath=\"fasttext_corpus.txt\"):\n",
        "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "        for text in df['clean_text']:\n",
        "            f.write(text + \"\\n\")\n",
        "\n",
        "    print(f\"Corpus saved to {filepath}\")\n",
        "\n",
        "\n",
        "# train or load fastText model\n",
        "def get_fasttext_model(corpus_path=\"fasttext_corpus.txt\", model_path=f\"fasttext_model_{YEAR_END}.bin\", force_retrain=False):\n",
        "\n",
        "    if not force_retrain and os.path.exists(model_path):\n",
        "        print(f\"Loading pre-trained model from {model_path}\")\n",
        "        return fasttext.load_model(model_path)\n",
        "\n",
        "    print(\"Training new FastText model...\")\n",
        "    model = fasttext.train_unsupervised(\n",
        "        corpus_path,\n",
        "        model='skipgram',\n",
        "        dim=300,\n",
        "        epoch=10,\n",
        "        minn=3,\n",
        "        maxn=6,\n",
        "        ws=10,\n",
        "        lr=0.05,\n",
        "        minCount=2,\n",
        "        thread=4)\n",
        "\n",
        "    model.save_model(model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdi4vR5JBlnM"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf7a0tLxBoVs"
      },
      "outputs": [],
      "source": [
        "\n",
        "# precision at k - fraction of relevant items in top k results\n",
        "def calculate_precision_at_k(ranked_list, validation_set, k):\n",
        "    top_k = ranked_list[:k]\n",
        "    hits = len(set(top_k) & validation_set)\n",
        "\n",
        "    return hits / k if k > 0 else 0\n",
        "\n",
        "# recall at k - fraction of relevant items found in top k\n",
        "def calculate_recall_at_k(ranked_list, validation_set, k):\n",
        "\n",
        "    top_k = ranked_list[:k]\n",
        "    hits = len(set(top_k) & validation_set)\n",
        "\n",
        "    return hits / len(validation_set) if len(validation_set) > 0 else 0\n",
        "\n",
        "# mean reciprocal rank of first relevant item\n",
        "def calculate_mrr(ranked_list, validation_set):\n",
        "\n",
        "    for i, item in enumerate(ranked_list):\n",
        "        if item in validation_set:\n",
        "            return 1 / (i + 1)\n",
        "    return 0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing fine-tuning BioBERT"
      ],
      "metadata": {
        "id": "WqWq2nDaw_2d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvh0WCj14nXH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# preparing corpus for fine-tuning BioBERT\n",
        "try:\n",
        "    df = pd.read_csv(f'als_articles_with_genes_{YEAR_END}.csv')\n",
        "\n",
        "    # Get the clean_text column and drop any empty rows\n",
        "    texts = df['clean_text'].dropna().tolist()\n",
        "\n",
        "    # Save the texts into a file, one abstract/text per line\n",
        "    with open('als_corpus_for_finetuning.txt', 'w', encoding='utf-8') as f:\n",
        "        for text in texts:\n",
        "            f.write(text + '\\n')\n",
        "\n",
        "    print(\"File 'als_corpus_for_finetuning.txt' created successfully.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'als_articles_with_genes.csv' not found. Please run the main data collection pipeline first (after the fine-tuning cell below).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeuKlD2f4pi6"
      },
      "outputs": [],
      "source": [
        "#!pip install datasets -q\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForMaskedLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "\n",
        "SAVE_PATH = \"./drive/MyDrive/IC_2025/biobert-finetuned-als_2010\"\n",
        "\n",
        "# loading the corpus\n",
        "try:\n",
        "    raw_datasets = load_dataset('text', data_files={'train': 'als_corpus_for_finetuning.txt'})\n",
        "    print(\"Corpus loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load corpus file. Error: {e}\")\n",
        "\n",
        "\n",
        "# loading pre-trained model and tokenizer\n",
        "model_checkpoint = \"dmis-lab/biobert-base-cased-v1.1\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "# AutoModelForMaskedLM because this is the architecture needed for MLM fine-tuning\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
        "\n",
        "# tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "tokenized_datasets = raw_datasets.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"]\n",
        ")\n",
        "\n",
        "\n",
        "# create batches and mask 15% of the tokens for training.\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=True,\n",
        "    mlm_probability=0.15\n",
        ")\n",
        "\n",
        "# training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=SAVE_PATH, # directory to save the new model\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=8,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,                # only keep the last 2 checkpoints\n",
        "    prediction_loss_only=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "# initialize and run the trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        ")\n",
        "\n",
        "print(\"\\nStarting the BioBERT fine-tuning process on the ALS corpus...\")\n",
        "trainer.train()\n",
        "print(\"Fine-tuning complete!\")\n",
        "\n",
        "# saving the model\n",
        "trainer.save_model(SAVE_PATH)\n",
        "tokenizer.save_pretrained(SAVE_PATH) #  save the tokenizer\n",
        "print(f\"Fine-tuned model saved to the directory {SAVE_PATH}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "uuEEePqmFUJD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKHXPyvLQlOH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score, ndcg_score\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "MODEL_CHOICE = 'fasttext' # choose your model: 'fasttext' or 'biobert'\n",
        "\n",
        "MODEL_MAP = {'biobert': 'dmis-lab/biobert-base-cased-v1.1'} # we may include more models in this dict\n",
        "\n",
        "VALIDATION_GENES = {\n",
        "    \"ANXA11\", \"C9ORF72\", \"CHCHD10\", \"EPHA4\", \"FUS\", \"HNRNPA1\", \"KIF5A\", \"NEK1\",\n",
        "    \"OPTN\", \"PFN1\", \"SOD1\", \"TARDBP\", \"TDP-43\", \"TDP43\", \"TBK1\", \"UBQLN2\",\n",
        "    \"UNC13A\", \"VAPB\", \"VCP\"\n",
        "}\n",
        "VALIDATION_GENES = {g.upper() for g in VALIDATION_GENES}\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    print(\"Starting pipeline...\\n\")\n",
        "\n",
        "    # data loading and processing\n",
        "    csv_path = f\"als_articles_with_genes_{YEAR_END}.csv\"\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    if os.path.exists(csv_path):\n",
        "        try:\n",
        "            df = pd.read_csv(csv_path)\n",
        "            if not df.empty and isinstance(df['genes'].iloc[0], str):\n",
        "                 df['genes'] = df['genes'].apply(lambda x: eval(x))\n",
        "            print(f\"Existing data loaded from {csv_path} ({len(df)} articles).\")\n",
        "        except (pd.errors.EmptyDataError, pd.errors.ParserError):\n",
        "            df = get_genetic_als_articles()\n",
        "    else:\n",
        "        df = get_genetic_als_articles()\n",
        "\n",
        "\n",
        "    # extracting and validating genes\n",
        "    if not df.empty:\n",
        "        if 'clean_text' not in df.columns:\n",
        "            df['text'] = df['text'].fillna('')\n",
        "            df['clean_text'] = df['text'].apply(clean_text)\n",
        "        if 'genes' not in df.columns:\n",
        "            df['genes'] = df['text'].apply(extract_genes_unbiased)\n",
        "\n",
        "            if VALIDATION_GENES and MYGENE_AVAILABLE:\n",
        "                valid_genes = validate_genes_with_mygene(set(g for gl in df['genes'] for g in gl))\n",
        "                df['genes'] = df['genes'].apply(lambda genes: [g for g in genes if g in valid_genes])\n",
        "        df.to_csv(csv_path, index=False)\n",
        "\n",
        "        print(f\"Processed data saved to '{csv_path}'.\")\n",
        "\n",
        "\n",
        "        print(\"\\nCalculating TF-IDF scores...\")\n",
        "        gene_scores = calculate_gene_scores(df)\n",
        "\n",
        "        # loading/training the model\n",
        "        embedding_model = None\n",
        "\n",
        "        if MODEL_CHOICE == 'biobert':\n",
        "            print(\"Initializing BioBERT...\")\n",
        "\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "            finetuned_model_path = \"./drive/MyDrive/IC_2025/biobert-finetuned-als_2010\"\n",
        "\n",
        "\n",
        "            tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n",
        "            model = AutoModel.from_pretrained(finetuned_model_path).to(device)\n",
        "            embedding_model = {'tokenizer': tokenizer, 'model': model, 'device': device}\n",
        "\n",
        "\n",
        "        elif MODEL_CHOICE == 'fasttext':\n",
        "            print(\"Initializing fastText...\")\n",
        "\n",
        "            corpus_filepath = \"fasttext_corpus.txt\"\n",
        "            model_filepath = f\"./drive/MyDrive/IC_2025/fasttext_model_{YEAR_END}.bin\"\n",
        "\n",
        "            if not os.path.exists(corpus_filepath):\n",
        "                save_corpus_for_fasttext(df, filepath=corpus_filepath)\n",
        "\n",
        "            embedding_model = get_fasttext_model(corpus_path=corpus_filepath, model_path=model_filepath)\n",
        "\n",
        "\n",
        "        # ranking\n",
        "        if embedding_model:\n",
        "            gene_score_dict = {gene.upper(): score for gene, score in gene_scores}\n",
        "\n",
        "            ranked_genes_full = calculate_combined_ranking(\n",
        "                gene_score_dict,\n",
        "                model=embedding_model,\n",
        "                model_type=MODEL_CHOICE,\n",
        "                alpha=0.5,    # 0.4 == 40% TF-IDF, 60% similarity --> test new values.\n",
        "                known_als_genes=VALIDATION_GENES\n",
        "            )\n",
        "\n",
        "            # metrics calculation (on list with known genes)\n",
        "            print(\"\\nCalculating performance metrics...\")\n",
        "\n",
        "            y_true = ranked_genes_full['gene'].str.upper().apply(lambda x: 1 if x in VALIDATION_GENES else 0).values\n",
        "            y_score = ranked_genes_full['combined'].values\n",
        "            ranked_list_full = ranked_genes_full['gene'].str.upper().tolist()\n",
        "\n",
        "            metrics = {\n",
        "                'P@10': calculate_precision_at_k(ranked_list_full, VALIDATION_GENES, 10),\n",
        "                'P@20': calculate_precision_at_k(ranked_list_full, VALIDATION_GENES, 20),\n",
        "                'R@50': calculate_recall_at_k(ranked_list_full, VALIDATION_GENES, 50),\n",
        "                'MAP': average_precision_score(y_true, y_score),\n",
        "                'nDCG': ndcg_score([y_true], [y_score]),\n",
        "                'MRR': calculate_mrr(ranked_list_full, VALIDATION_GENES)\n",
        "            }\n",
        "            metrics_df = pd.DataFrame([metrics], index=[MODEL_CHOICE.capitalize()])\n",
        "\n",
        "            # filtering for novel candidates\n",
        "            ranked_novel_genes = ranked_genes_full[~ranked_genes_full['gene'].isin(VALIDATION_GENES)]\n",
        "\n",
        "\n",
        "\n",
        "            # to make temporal analysis --> use ranked_genes_full\n",
        "            # to discover new candidate genes --> use ranked_novel_genes\n",
        "\n",
        "            if not ranked_novel_genes.empty:\n",
        "                print(f\"\\n--- TOP 20 NOVEL CANDIDATES (Model: {MODEL_CHOICE.upper()}) ---\")\n",
        "                for i, row in enumerate(ranked_novel_genes.head(20).itertuples(), 1):\n",
        "                    print(f\"{i}. {row.gene.upper():<10} | Score: {row.combined:.4f} (TF-IDF: {row.tfidf_raw_norm:.4f}, Sim: {row.sim_raw_norm:.4f})\")\n",
        "\n",
        "                output_filename = f'als_novel_gene_candidates_{MODEL_CHOICE}.csv'\n",
        "                ranked_novel_genes.to_csv(output_filename, index=False)\n",
        "                print(f\"\\nResults with novel genes saved to '{output_filename}'\")\n",
        "\n",
        "            print(\"\\n--- Performance Metrics Table ---\")\n",
        "            print(metrics_df.round(4))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"genes\"]"
      ],
      "metadata": {
        "id": "E-f60QPHW6rW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Temporal validation"
      ],
      "metadata": {
        "id": "A4cpbDRj8xib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "GENE_TO_QUERY = \"KIF5A\"\n",
        "MODEL_TO_USE = 'fasttext'\n",
        "\n",
        "VALIDATION_GENES = {\n",
        "    \"ANXA11\", \"C9ORF72\", \"CHCHD10\", \"EPHA4\", \"FUS\", \"HNRNPA1\", \"KIF5A\", \"NEK1\",\n",
        "    \"OPTN\", \"PFN1\", \"SOD1\", \"TARDBP\", \"TBK1\", \"UBQLN2\",\n",
        "    \"UNC13A\", \"VAPB\", \"VCP\"\n",
        "}\n",
        "VALIDATION_GENES = {g.upper() for g in VALIDATION_GENES}\n",
        "\n",
        "\n",
        "print(f\"Loading the model... '{MODEL_TO_USE}'...\")\n",
        "embedding_model = None\n",
        "\n",
        "if MODEL_TO_USE == 'biobert':\n",
        "    FINETUNED_MODEL_PATH = \"./drive/MyDrive/IC_2025/biobert-finetuned-als_2010\"\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL_PATH)\n",
        "    model = AutoModel.from_pretrained(FINETUNED_MODEL_PATH).to(device)\n",
        "    embedding_model = {'tokenizer': tokenizer, 'model': model, 'device': device}\n",
        "\n",
        "elif MODEL_TO_USE == 'fasttext':\n",
        "    model_filepath = f\"./drive/MyDrive/IC_2025/fasttext_model_{YEAR_END}.bin\"\n",
        "    embedding_model = fasttext.load_model(model_filepath)\n",
        "\n",
        "df_full = pd.read_csv('als_articles_with_genes_2010.csv')\n",
        "df_full['genes'] = df_full['genes'].apply(lambda x: eval(x))\n",
        "all_genes_in_corpus = set(g.upper() for gene_list in df_full['genes'] for g in gene_list)\n",
        "\n",
        "\n",
        "\n",
        "def find_similar_genes_within_set(input_gene, model, model_type, comparison_set):\n",
        "\n",
        "    print(f\"\\nCalculating similarity of '{input_gene.upper()}' with reference set...\")\n",
        "    input_gene_upper = input_gene.upper()\n",
        "    comparison_set_upper = {g.upper() for g in comparison_set}\n",
        "    comparison_set_upper.discard(input_gene_upper)\n",
        "    genes_to_embed = [input_gene_upper] + list(comparison_set_upper)\n",
        "    all_embeddings, valid_genes_list = get_embeddings(genes_to_embed, model, model_type)\n",
        "\n",
        "    if input_gene_upper not in valid_genes_list:\n",
        "        print(f\"ERROR: Candidate gene '{input_gene_upper}' was not found in the model's vocabulary.\")\n",
        "        return None\n",
        "\n",
        "    all_embeddings = normalize(all_embeddings)\n",
        "    input_embedding = all_embeddings[0].reshape(1, -1)\n",
        "    comparison_embeddings = all_embeddings[1:]\n",
        "    comparison_genes = valid_genes_list[1:]\n",
        "    similarities = cosine_similarity(input_embedding, comparison_embeddings)\n",
        "    results = sorted(zip(comparison_genes, similarities[0]), key=lambda item: item[1], reverse=True)\n",
        "    print(f\"\\n--- Similarity ranking with '{input_gene_upper}' (Model: {model_type.capitalize()}) ---\")\n",
        "    for gene, score in results:\n",
        "        print(f\"{gene:<12} | Similarity: {score:.4f}\")\n",
        "    return results\n",
        "\n",
        "\n",
        "if embedding_model:\n",
        "    if GENE_TO_QUERY.upper() in all_genes_in_corpus:\n",
        "\n",
        "        # reference set should be both in validation genes and in model's vocab\n",
        "        final_comparison_set = VALIDATION_GENES.intersection(all_genes_in_corpus)\n",
        "\n",
        "        print(f\"\\nIniciando anÃ¡lise. Comparando com {len(final_comparison_set)} genes validados que estÃ£o presentes no corpus.\")\n",
        "\n",
        "        similarity_results = find_similar_genes_within_set(GENE_TO_QUERY, embedding_model, MODEL_TO_USE, final_comparison_set)\n",
        "\n",
        "\n",
        "        if similarity_results:\n",
        "\n",
        "            top_10_results = similarity_results[:10]\n",
        "            df_plot = pd.DataFrame(top_10_results, columns=['gene', 'similarity'])\n",
        "            df_plot = df_plot.sort_values('similarity', ascending=True)\n",
        "            plt.style.use('seaborn-v0_8-whitegrid')\n",
        "            plt.figure(figsize=(10, 7), dpi=120)\n",
        "            plt.barh(df_plot['gene'], df_plot['similarity'], color='skyblue', edgecolor='black')\n",
        "            plt.xlabel('Cosine Similarity', fontsize=12)\n",
        "            plt.title(f'Top Most Similar ALS Genes to \"{GENE_TO_QUERY.upper()}\"', fontsize=16, weight='bold')\n",
        "            plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
        "            plt.tight_layout()\n",
        "            plt.savefig(f'similarity_plot_{GENE_TO_QUERY.upper()}.png', dpi=300)\n",
        "            plt.show()\n",
        "\n",
        "    else:\n",
        "        print(f\"\\nERROR: Gene '{GENE_TO_QUERY.upper()}' not found on the list of genes of the corpus..\")\n",
        "else:\n",
        "    print(f\"Model '{MODEL_TO_USE}' could not be loaded.\")"
      ],
      "metadata": {
        "id": "O-FEifle8xPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM1Kzz4p0dmi"
      },
      "source": [
        "# Plotting the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nRqye5l0xQJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "def plot_separate_score_charts(model_choice: str, num_genes: int = 20):\n",
        "    \"\"\"\n",
        "      Loads model results and generates two separate bar charts for the TF-IDF\n",
        "      and Semantic Similarity scores of the top N candidate genes.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # loads data\n",
        "    results_filename = f'als_novel_gene_candidates_{model_choice}.csv'\n",
        "    try:\n",
        "        ranked_genes_df = pd.read_csv(results_filename)\n",
        "        print(f\"Loaded data from '{results_filename}'\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The results file '{results_filename}' was not found.\")\n",
        "        print(\"Please run the main pipeline cell first to generate the results.\")\n",
        "        return\n",
        "\n",
        "    # select the top N genes based on the overall combined score\n",
        "    top_genes = ranked_genes_df.head(num_genes)\n",
        "\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, axes = plt.subplots(\n",
        "        1, 2,  # 1 row, 2 columns\n",
        "        figsize=(20, 10),\n",
        "        dpi=150\n",
        "    )\n",
        "\n",
        "\n",
        "    # sort data by TF-IDF score for this plot\n",
        "    tfidf_sorted = top_genes.sort_values('tfidf_raw_norm', ascending=True)\n",
        "\n",
        "    axes[0].barh(\n",
        "        tfidf_sorted['gene'].str.upper(),\n",
        "        tfidf_sorted['tfidf_raw_norm'],\n",
        "        color='skyblue'\n",
        "    )\n",
        "    axes[0].set_title('Top 20 Gene Candidates by TF-IDF Score', fontsize=16, weight='bold')\n",
        "    axes[0].set_xlabel('TF-IDF Score', fontsize=12)\n",
        "    axes[0].tick_params(axis='y', labelsize=11)\n",
        "    axes[0].grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "\n",
        "\n",
        "    # sort data by similarity score for this plot\n",
        "    sim_sorted = top_genes.sort_values('sim_raw_norm', ascending=True)\n",
        "\n",
        "    axes[1].barh(\n",
        "        sim_sorted['gene'].str.upper(),\n",
        "        sim_sorted['sim_raw_norm'],\n",
        "        color='salmon'\n",
        "    )\n",
        "    axes[1].set_title('Top 20 Gene Candidates by Semantic Similarity Score', fontsize=16, weight='bold')\n",
        "    axes[1].set_xlabel('Semantic Similarity Score ', fontsize=12)\n",
        "    axes[1].tick_params(axis='y', labelsize=11) # Adjust y-axis label size\n",
        "    axes[1].grid(axis='x', linestyle='--', alpha=0.7)\n",
        "\n",
        "\n",
        "    fig.suptitle(\n",
        "        f'Score Analysis of Top Gene Candidates (fastText)',\n",
        "        fontsize=20,\n",
        "        weight='bold'\n",
        "    )\n",
        "\n",
        "    # adjust layout\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
        "\n",
        "    # saving figure\n",
        "    output_fig_filename = f'separate_scores_visualization_{model_choice}.png'\n",
        "    plt.savefig(output_fig_filename, dpi=300)\n",
        "    print(f\"Figure saved as '{output_fig_filename}'\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "model_to_visualize = 'fasttext' # 'fasttext', 'biobert'\n",
        "\n",
        "plot_separate_score_charts(model_choice=model_to_visualize)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Network Analysis"
      ],
      "metadata": {
        "id": "bp3qYtMDFKbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx python-louvain -q"
      ],
      "metadata": {
        "id": "8qP2fheHFb7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import community.community_louvain as community_louvain\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import normalize\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "\n",
        "FINETUNED_MODEL_PATH = \"./drive/MyDrive/IC_2025/biobert-finetuned-als\"\n",
        "SIMILARITY_THRESHOLD = 0.9  # similarity threshold\n",
        "\n",
        "\n",
        "# loading and generating embeddings\n",
        "print(\"Loading data and generating embeddings for all genes...\")\n",
        "\n",
        "df_full = pd.read_csv('als_articles_with_genes.csv')\n",
        "df_full['genes'] = df_full['genes'].apply(lambda x: eval(x))\n",
        "\n",
        "all_genes_in_corpus = sorted(list(set(g.upper() for gene_list in df_full['genes'] for g in gene_list)))\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = AutoTokenizer.from_pretrained(FINETUNED_MODEL_PATH)\n",
        "model = AutoModel.from_pretrained(FINETUNED_MODEL_PATH).to(device)\n",
        "model_components = {'tokenizer': tokenizer, 'model': model, 'device': device}\n",
        "\n",
        "# getting embeddings\n",
        "all_embeddings, all_genes_list = get_embeddings(all_genes_in_corpus, model_components, 'biobert')\n",
        "all_embeddings = normalize(all_embeddings)\n",
        "\n",
        "print(f\"Generated embeddings for {len(all_genes_list)} unique genes.\")\n",
        "\n",
        "\n",
        "# creating the network\n",
        "print(f\"\\nCreating similarity network with threshold: {SIMILARITY_THRESHOLD}...\")\n",
        "\n",
        "similarity_matrix = cosine_similarity(all_embeddings)\n",
        "\n",
        "G = nx.Graph()\n",
        "for i in range(len(all_genes_list)):\n",
        "    G.add_node(all_genes_list[i])\n",
        "    for j in range(i + 1, len(all_genes_list)):\n",
        "        if similarity_matrix[i, j] > SIMILARITY_THRESHOLD:\n",
        "            G.add_edge(all_genes_list[i], all_genes_list[j], weight=similarity_matrix[i, j])\n",
        "\n",
        "print(f\"Initial network: {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
        "\n",
        "# removing isolated nodes\n",
        "G.remove_nodes_from(list(nx.isolates(G)))\n",
        "print(f\"Filtered network (no isolates): {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n",
        "\n",
        "\n",
        "# network metrics\n",
        "print(\"\\n--- Network Analysis Results ---\")\n",
        "\n",
        "avg_clustering = nx.average_clustering(G)\n",
        "print(f\"Average Clustering Coefficient: {avg_clustering:.4f}\")\n",
        "\n",
        "print(\"\\nTop 10 Genes by Betweenness Centrality:\")\n",
        "betweenness = nx.betweenness_centrality(G)\n",
        "sorted_betweenness = sorted(betweenness.items(), key=lambda item: item[1], reverse=True)\n",
        "for gene, score in sorted_betweenness[:10]:\n",
        "    print(f\"- {gene}: {score:.4f}\")\n",
        "\n",
        "print(\"\\nDetecting community structure with Louvain algorithm...\")\n",
        "partition = community_louvain.best_partition(G)\n",
        "modularity = community_louvain.modularity(partition, G)\n",
        "num_communities = len(set(partition.values()))\n",
        "\n",
        "print(f\"Number of communities detected: {num_communities}\")\n",
        "print(f\"Modularity Score: {modularity:.4f}\")\n",
        "\n",
        "print(\"\\nGenes in the largest communities:\")\n",
        "community_sizes = pd.Series(partition).value_counts()\n",
        "for i in range(min(5, num_communities)):\n",
        "    community_id = community_sizes.index[i]\n",
        "    community_genes = [node for node, com in partition.items() if com == community_id]\n",
        "    print(f\"\\nCommunity {community_id} ({len(community_genes)} genes):\")\n",
        "    print(\", \".join(community_genes[:15]) + ('...' if len(community_genes) > 15 else ''))\n",
        "\n",
        "\n",
        "# full network\n",
        "print(\"\\nGenerating network visualization...\")\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "pos = nx.spring_layout(G, seed=42)\n",
        "\n",
        "colors = [partition[node] for node in G.nodes()]\n",
        "degrees = dict(G.degree())\n",
        "node_sizes = [degrees[node] * 50 for node in G.nodes()]  # size is proportional to degree\n",
        "\n",
        "nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color=colors, cmap=plt.cm.jet)\n",
        "nx.draw_networkx_edges(G, pos, alpha=0.3)\n",
        "\n",
        "plt.title(\"Gene Similarity Network (Colored by Community, Node Size ~ Degree)\", fontsize=20)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# plot top communities\n",
        "print(\"\\nPlotting top communities...\")\n",
        "\n",
        "partition = community_louvain.best_partition(G)\n",
        "community_sizes = pd.Series(partition).value_counts()\n",
        "num_top_communities_to_plot = 3\n",
        "\n",
        "for i in range(min(num_top_communities_to_plot, len(community_sizes))):\n",
        "    community_id = community_sizes.index[i]\n",
        "    community_nodes = [node for node, com in partition.items() if com == community_id]\n",
        "    community_graph = G.subgraph(community_nodes)\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    pos = nx.spring_layout(community_graph, seed=42, k=0.5, iterations=100)\n",
        "\n",
        "    degrees_sub = dict(community_graph.degree())\n",
        "    node_sizes_sub = [degrees_sub[node] * 100 for node in community_graph.nodes()]\n",
        "\n",
        "    nx.draw_networkx_nodes(community_graph, pos, node_size=node_sizes_sub, node_color='skyblue')\n",
        "    nx.draw_networkx_edges(community_graph, pos, alpha=0.6, edge_color='gray')\n",
        "    nx.draw_networkx_labels(community_graph, pos, font_size=10)\n",
        "\n",
        "    plt.title(f\"Community {community_id} ({community_graph.number_of_nodes()} Genes)\", fontsize=20, weight='bold')\n",
        "    output_fig_filename = f'network_community_{community_id}.png'\n",
        "    plt.savefig(output_fig_filename, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "Nb0zm4biFd62"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}